{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4ab522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "import ipaddress\n",
    "\n",
    "SEED = 7\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(SEED)\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Activation, GlobalAveragePooling2D, Input\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow.keras.applications import NASNetLarge\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "NETWORK = InceptionV3\n",
    "\n",
    "# from kaggle_datasets import KaggleDatasets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, classification_report\n",
    "\n",
    "\n",
    "import re\n",
    "import imageio\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd2f26c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of replicas: 1\n",
      "Tensorflow version  2.12.0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = None\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Device:', tpu.master())\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "except:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "print('Number of replicas:', strategy.num_replicas_in_sync)\n",
    "    \n",
    "print(\"Tensorflow version \", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ecb6729",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from kaggle_secrets import UserSecretsClient\n",
    "#user_secrets = UserSecretsClient()\n",
    "#user_credential = user_secrets.get_gcloud_credential()\n",
    "\n",
    "#user_secrets.set_tensorflow_credential(user_credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b7a1b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "class CosineAnnealingScheduler(Callback):\n",
    "\n",
    "    def __init__(self, T_max, eta_max, eta_min=0, verbose=0):\n",
    "        super(CosineAnnealingScheduler, self).__init__()\n",
    "        self.T_max = T_max\n",
    "        self.eta_max = eta_max\n",
    "        self.eta_min = eta_min\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if not hasattr(self.model.optimizer, 'lr'):\n",
    "            raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
    "        lr = self.eta_min + (self.eta_max - self.eta_min) * (1 + math.cos(math.pi * epoch / self.T_max)) / 2\n",
    "        K.set_value(self.model.optimizer.lr, lr)\n",
    "        if self.verbose > 0:\n",
    "            print('\\nEpoch %05d: CosineAnnealingScheduler setting learning '\n",
    "                  'rate to %s.' % (epoch + 1, lr))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        logs['lr'] = K.get_value(self.model.optimizer.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4c9b39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "decay is deprecated in the new Keras optimizer, pleasecheck the docstring for valid arguments, or use the legacy optimizer, e.g., tf.keras.optimizers.legacy.Adam.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3180/339026605.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mEarly_Stop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mOPTIMIZER\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m Callbacks = [\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\optimizers\\adam.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, learning_rate, beta_1, beta_2, epsilon, amsgrad, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, name, **kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     ):\n\u001b[1;32m--> 104\u001b[1;33m         super().__init__(\n\u001b[0m\u001b[0;32m    105\u001b[0m             \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, **kwargs)\u001b[0m\n\u001b[0;32m   1085\u001b[0m         \u001b[1;34m\"\"\"Create a new Optimizer.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1087\u001b[1;33m         super().__init__(\n\u001b[0m\u001b[0;32m   1088\u001b[0m             \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1089\u001b[0m             \u001b[0mweight_decay\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_iteration_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_create_iteration_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer.py\u001b[0m in \u001b[0;36m_process_kwargs\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlegacy_kwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    135\u001b[0m                     \u001b[1;34mf\"{k} is deprecated in the new Keras optimizer, please\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                     \u001b[1;34m\"check the docstring for valid arguments, or use the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: decay is deprecated in the new Keras optimizer, pleasecheck the docstring for valid arguments, or use the legacy optimizer, e.g., tf.keras.optimizers.legacy.Adam."
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "tf.config.optimizer.set_jit(True)\n",
    "\n",
    "Epochs = 1\n",
    "\n",
    "dataset_id1 = 'covid19-lung-ct-scans'\n",
    "# GCS_PATH1 = KaggleDatasets().get_gcs_path(dataset_id1)\n",
    "GCS_PATH1 = '.'\n",
    "BATCH_SIZE = 128 * strategy.num_replicas_in_sync\n",
    "\n",
    "CLASSES = ['COVID-19', 'Non-COVID-19']\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "IMAGE_SIZE = [224, 224]\n",
    "input_shape = (224, 224, 3)\n",
    "LOSS = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2)\n",
    "\n",
    "Early_Stop = 15\n",
    "OPTIMIZER = tensorflow.keras.optimizers.Adam(lr = 1e-2, decay = 1e-5)\n",
    "\n",
    "Callbacks = [\n",
    "    CosineAnnealingScheduler(Epochs, 1e-3, 1e-6),\n",
    "    EarlyStopping(monitor='val_accuracy', patience=Early_Stop, mode='auto', min_delta=0.00001, verbose=2, restore_best_weights=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6c5224",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = tf.io.gfile.glob(str(GCS_PATH1 + '/COVID-19_Lung_CT_Scans/COVID-19/*'))\n",
    "filenames.extend(tf.io.gfile.glob(str(GCS_PATH1 + '/COVID-19_Lung_CT_Scans/Non-COVID-19/*')))\n",
    "#filenames.remove(str(GCS_PATH1 + '/COVID-19_Lung_CT_Scans/COVID-19/desktop.ini'))\n",
    "    \n",
    "random.shuffle(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a8fd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNT_COVID = len([filename for filename in filenames if \"\\\\COVID-19\\\\\" in filename])\n",
    "print(\"COVID-19 images count : \" + str(COUNT_COVID))\n",
    "\n",
    "COUNT_Non_COVID = len([filename for filename in filenames if \"\\\\Non-COVID-19\\\\\" in filename])\n",
    "print(\"Non-COVID images count : \" + str(COUNT_Non_COVID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf9d635",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Cases':['COVID-19', 'non-COVID'],\n",
    "        'Cases_count':[COUNT_COVID, COUNT_Non_COVID]\n",
    "       }\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.barplot(x=df.index, y= df['Cases_count'].values)\n",
    "plt.title('Number of All the Data', fontsize=14)\n",
    "plt.xlabel('Case type', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks(range(len(df.index)), ['COVID-19', 'non-COVID'])\n",
    "plt.show()\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a89512",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filenames, test_filenames = train_test_split(filenames, test_size=0.2)\n",
    "train_filenames, val_filenames = train_test_split(train_filenames, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a08e2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2793dd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list_ds = tf.data.Dataset.from_tensor_slices(train_filenames)\n",
    "val_list_ds = tf.data.Dataset.from_tensor_slices(val_filenames)\n",
    "test_list_ds = tf.data.Dataset.from_tensor_slices(test_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ffb98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMG_COUNT = tf.data.experimental.cardinality(train_list_ds).numpy()\n",
    "print(\"Training images count: \" + str(TRAIN_IMG_COUNT))\n",
    "\n",
    "VAL_IMG_COUNT = tf.data.experimental.cardinality(val_list_ds).numpy()\n",
    "print(\"Validating images count: \" + str(VAL_IMG_COUNT))\n",
    "\n",
    "Test_IMG_COUNT = tf.data.experimental.cardinality(test_list_ds).numpy()\n",
    "print(\"Testing images count: \" + str(Test_IMG_COUNT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb29e544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    print(int(parts[1] == CLASSES))\n",
    "    return int(parts[1] == CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f6c1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(img):\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    return tf.image.resize(img, IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22336de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fc4aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "test_ds = test_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831684d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_training(ds, cache=True):\n",
    "    ds = ds.shuffle(buffer_size=1000)\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "\n",
    "    if cache:\n",
    "        ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e61af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_augmentation = Sequential([\n",
    "    preprocessing.RandomFlip(\"horizontal\"),\n",
    "    preprocessing.RandomContrast(factor=0.20)\n",
    "    ],name=\"Augmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0dfe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(image_batch, label_batch):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for n in range(15):\n",
    "        ax = plt.subplot(1,5,n+1)\n",
    "        plt.imshow(image_batch[n])\n",
    "        plt.title(CLASSES[np.argmax(label_batch[n])])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec9b0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(train_ds))\n",
    "show_batch(image_batch.numpy(), label_batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18f4eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_numpy_util(dataset, N):\n",
    "    dataset = dataset.unbatch().batch(N)\n",
    "    for images, labels in dataset:\n",
    "        numpy_images = images.numpy()\n",
    "        numpy_labels = labels.numpy()\n",
    "        break\n",
    "    return numpy_images, numpy_labels\n",
    "\n",
    "x_test, y_test = dataset_to_numpy_util(test_ds, Test_IMG_COUNT)\n",
    "\n",
    "print(\"Evaluation Dataset:\")\n",
    "print('X shape: ', x_test.shape,' Y shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013bc042",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
